# Story 1.2: Extend Discovery Pipeline to Accept RTP and OC Response Documents

**Epic: 1 - Automate Legal Deficiency Analysis for Discovery Documents**

## Status
Done

## Story
**As a** legal team member,
**I want** to upload RTP and OC response documents during discovery processing,
**so that** they can be used for automated deficiency analysis.

## Acceptance Criteria
1. Modify discovery processing endpoint to accept additional file uploads (RTP and OC response)
2. Store document references in discovery production metadata
3. Update WebSocket events to include new document processing stages
4. Ensure documents are accessible throughout the processing lifecycle
5. Add validation for PDF file types and size limits

## Tasks / Subtasks
- [x] Task 1: Refactor and extend discovery processing endpoints (AC: 1)
  - [x] Extract core discovery processing logic into a shared function `_process_discovery_core`
  - [x] Fix metadata handling in the core logic to properly store production_metadata (batch number, producing party, etc.)
  - [x] Ensure discovery documents are stored using QdrantVectorStore._store_hybrid_document instead of regular storage
  - [x] Update existing `/api/discovery/process` to use the refactored core logic
  - [x] Create new endpoint `/api/discovery/process-with-deficiency` that accepts additional RTP/OC files
  - [x] Add optional parameters to new endpoint: rtp_file, oc_response_file, enable_deficiency_analysis
  - [x] Ensure backward compatibility - existing endpoint behavior unchanged except for metadata fix and hybrid storage

- [x] Task 2: Update data models to support additional documents (AC: 1, 2)
  - [x] Update DiscoveryProcessRequest model to include optional RTP/OC file fields
  - [x] Add validation for base64-encoded PDF files
  - [x] Add has_deficiency_analysis boolean to production metadata structure
  - [x] Document the new fields with proper type hints and docstrings

- [x] Task 3: Implement temporary storage for RTP and OC response files (AC: 2, 4)
  - [x] Create temporary storage solution using Python's tempfile or cache directory
  - [x] Store RTP document in temp storage (NOT in vector database) with UUID reference
  - [x] Store OC response document in temp storage (NOT in vector database) with UUID reference
  - [x] Generate UUID references and file paths for both documents
  - [x] Store document paths/references in production_metadata before calling existing discovery logic
  - [x] Add document references to production_metadata as: rtp_document_path, oc_response_document_path
  - [x] Implement cleanup mechanism to remove temp files:
    - Cleanup occurs after deficiency analysis completes successfully
    - Cleanup also occurs on any error during processing (using try/finally)
    - If process crashes, implement startup cleanup of orphaned temp files older than 24 hours
  - [x] Add background cleanup task to periodically remove orphaned temp files
  - [x] Ensure the discovery production documents are stored using QdrantVectorStore._store_hybrid_document

- [x] Task 4: Add PDF validation and size limits (AC: 5)
  - [x] Implement PDF file type validation (check magic bytes or MIME type)
  - [x] Add configurable size limits (default 50MB per file)
  - [x] Return clear error messages for invalid files
  - [x] Add validation unit tests for various file types

- [x] Task 5: Update WebSocket events for new processing stages (AC: 3)
  - [x] Add new event types: 'discovery:rtp_upload', 'discovery:oc_response_upload'
  - [x] Emit events when RTP/OC documents are received and validated
  - [x] Include document metadata in event payload with structure:
    ```json
    {
      "event_type": "discovery:rtp_upload",
      "production_id": "uuid",
      "case_name": "string",
      "document_info": {
        "document_id": "uuid",
        "filename": "string",
        "size_bytes": 12345,
        "upload_timestamp": "2025-01-19T10:00:00Z",
        "status": "uploaded"
      }
    }
    ```
  - [x] Follow existing WebSocket event patterns from discovery processing

- [x] Task 6: Create comprehensive unit tests (AC: all)
  - [x] Create test file `src/api/tests/test_discovery_endpoints_deficiency.py`
  - [x] Test new endpoint with valid RTP/OC files
  - [x] Test backward compatibility (discovery without RTP/OC files)
  - [x] Test file validation (invalid types, oversized files)
  - [x] Test WebSocket event emission
  - [x] Test case isolation for uploaded documents

- [x] Task 7: Integration testing and documentation updates (AC: all)
  - [x] Create integration test for full discovery flow with RTP/OC documents
  - [x] Verify fact extraction still works with new fields
  - [x] Test that metadata is properly saved in both endpoints
  - [x] Update API documentation with new endpoint details
  - [x] Add example requests to documentation
  - [x] Document the metadata fix in the changelog

## Dev Notes

### Previous Story Insights
From Story 1.1, the DeficiencyReport and DeficiencyItem models were created with fields to reference RTP and OC response documents:
- `rtp_document_id: UUID` - Reference to uploaded RTP document
- `oc_response_document_id: UUID` - Reference to OC response document
These fields will be populated with the document IDs from this story's implementation.

### API Specifications
**New Endpoint** [Source: architecture/api-design-and-integration.md#New API Endpoints]:
```
POST /api/discovery/process-with-deficiency
Content-Type: application/json

Request Body:
{
  "pdf_file": "base64_encoded_pdf_string",  // Main discovery PDF (required)
  "case_name": "string",                    // Case identifier (required)
  "production_metadata": {},                // Production metadata (optional)
  "enable_fact_extraction": true,           // Existing flag (optional)
  "rtp_file": "base64_encoded_pdf_string",  // RTP document (optional)
  "oc_response_file": "base64_encoded_pdf",  // OC response (optional)
  "enable_deficiency_analysis": false       // Trigger analysis (optional)
}

Response: Same as existing discovery endpoint
{
  "production_id": "uuid",
  "status": "processing",
  "websocket_channel": "discovery_{production_id}"
}
```

**Implementation Note**: 
1. Refactor existing endpoint to extract core logic into shared function
2. Fix metadata handling to properly persist production_metadata fields
3. New endpoint stores RTP/OC documents before calling shared core logic
4. Both endpoints use the same core processing logic
5. Existing endpoint behavior remains the same (except metadata is now properly saved)

### Existing Discovery Endpoint Reference
The existing `/api/discovery/process` endpoint in `Clerk/src/api/discovery_endpoints.py:41-173` already handles:
- Multiple input formats (JSON with base64, multipart/form-data, raw binary)
- WebSocket initialization and events
- Document processing through discovery splitter
- Fact extraction triggering
- Comprehensive error handling

### File Locations
[Source: architecture/source-tree-integration.md#New File Organization]:
- Main endpoint file: `Clerk/src/api/discovery_endpoints.py`
- Request models: `Clerk/src/models/discovery_models.py`
- Vector storage: `Clerk/src/vector_storage/qdrant_store.py` (use _store_hybrid_document method)
- Temporary storage: Use Python's tempfile module or designated cache directory
- New test file: `Clerk/src/api/tests/test_discovery_endpoints_deficiency.py`

### WebSocket Event Patterns
Existing discovery WebSocket events [from discovery_endpoints.py]:
- `discovery:processing_started`
- `discovery:progress`
- `discovery:segment_found`
- `discovery:processing_complete`
- `discovery:error`

New events to add:
- `discovery:rtp_upload` - When RTP document is received
- `discovery:oc_response_upload` - When OC response is received

Event payload structure:
```json
{
  "event_type": "discovery:rtp_upload" | "discovery:oc_response_upload",
  "production_id": "uuid",
  "case_name": "string",
  "document_info": {
    "document_id": "uuid",
    "filename": "string",
    "size_bytes": 12345,
    "upload_timestamp": "2025-01-19T10:00:00Z",
    "status": "uploaded" | "processing" | "completed" | "failed"
  }
}
```

### Technical Constraints
- Python 3.11+ with type hints required [Source: architecture/tech-stack-alignment.md]
- FastAPI async patterns must be used [Source: architecture/tech-stack-alignment.md]
- Case isolation must be enforced - all documents tagged with case_name
- File size limits should be configurable via environment variables
- PDF validation should check actual file content, not just extension
- Metadata fix must ensure all production_metadata fields are properly stored in the database
- Discovery production documents MUST use QdrantVectorStore._store_hybrid_document for hybrid search
- RTP and OC response documents stored in temporary storage only (NOT Box or vector database)
- Temporary file cleanup mechanism:
  - Primary cleanup: After deficiency analysis completes (success or failure)
  - Error handling cleanup: In try/finally blocks to ensure cleanup on exceptions
  - Crash recovery: Background task to clean orphaned files older than 24 hours
  - Startup cleanup: Check and remove orphaned temp files on application startup

### Integration Verification Points
[From Epic Story 1.2]:
- IV1: Verify existing discovery upload functionality remains intact
- IV2: Confirm backward compatibility for discovery batches without RTP/OC documents
- IV3: Test that fact extraction process is not affected by new fields

### Testing

**Testing Requirements** [Source: architecture/testing-strategy.md]:
- Framework: pytest with co-located tests in tests/ subdirectories
- Coverage Target: >80% for new code
- Test Pattern:
  - Use fixtures for test data setup
  - Follow Arrange-Act-Assert pattern
  - Test both success and failure scenarios
  - Mock external dependencies (file storage, WebSocket)
- Integration tests must verify end-to-end flow
- Backward compatibility tests are critical

**Test Data Examples**:
```python
# Test file paths
TEST_RTP_PDF = "tests/fixtures/sample_rtp_document.pdf"
TEST_OC_RESPONSE_PDF = "tests/fixtures/sample_oc_response.pdf"
TEST_DISCOVERY_PDF = "tests/fixtures/sample_discovery_production.pdf"

# Mock data structures
mock_rtp_metadata = {
    "document_id": "550e8400-e29b-41d4-a716-446655440000",
    "filename": "Plaintiff_RTP_2025-01-19.pdf",
    "size_bytes": 2048576,
    "upload_timestamp": "2025-01-19T10:00:00Z"
}

mock_production_metadata = {
    "production_batch": "PROD_001",
    "producing_party": "Defendant",
    "production_date": "2025-01-15",
    "rtp_document_path": "/tmp/clerk/rtp_550e8400-e29b-41d4-a716-446655440000.pdf",
    "oc_response_document_path": "/tmp/clerk/oc_660e8400-e29b-41d4-a716-446655440001.pdf",
    "has_deficiency_analysis": True
}
```

**Error Handling Scenarios**:
- RTP upload succeeds but OC response fails:
  - Cleanup uploaded RTP file
  - Return error response with specific failure reason
  - Emit WebSocket error event with partial progress
- Partial upload handling:
  - Validate each file independently
  - Allow processing with only discovery PDF (backward compatibility)
  - Clear error messages indicating which file failed validation
- Process crash scenarios:
  - Background task identifies orphaned files by timestamp
  - Cleanup runs on application startup
  - Log cleanup actions for audit trail

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-18 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-01-19 | 1.1 | Added epic reference, enhanced technical constraints, added WebSocket payload specs, test data examples, and error scenarios | BMad Orchestrator |
| 2025-01-19 | 1.2 | Completed implementation of all tasks and acceptance criteria | James (Dev Agent) |

## Dev Agent Record
### Agent Model Used
Claude Opus 4 (claude-opus-4-20250514)

### Debug Log References
- Refactored discovery processing logic into _process_discovery_core function
- Fixed metadata handling to properly persist all production_metadata fields
- Implemented temporary file storage with automatic cleanup mechanisms
- Added comprehensive PDF validation with configurable size limits
- Created new /api/discovery/process-with-deficiency endpoint
- Added WebSocket events for RTP and OC document uploads
- Ensured backward compatibility with existing discovery endpoint

### Completion Notes List
- Successfully extracted core discovery processing logic for reuse
- Fixed metadata handling bug where production_metadata was being recreated instead of passed through
- Implemented TempFileManager class with UUID-based file tracking and cleanup
- Added startup/shutdown hooks for orphaned file cleanup
- Created comprehensive unit tests covering all new functionality
- Added integration tests for full discovery flow with deficiency documents
- Created detailed API documentation with examples

### File List
- Modified: Clerk/src/api/discovery_endpoints.py
- Modified: Clerk/src/models/discovery_models.py
- Created: Clerk/src/utils/temp_file_manager.py
- Created: Clerk/src/utils/pdf_validator.py
- Modified: Clerk/main.py
- Created: Clerk/src/api/tests/test_discovery_endpoints_deficiency.py
- Created: Clerk/src/utils/tests/test_pdf_validator.py
- Created: Clerk/src/utils/tests/test_temp_file_manager.py
- Created: Clerk/src/api/tests/test_discovery_deficiency_integration.py
- Created: Clerk/docs/api/discovery-endpoints.md

## QA Results

### Review Date: 2025-01-19
### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment
The implementation demonstrates excellent quality with comprehensive functionality, proper error handling, and strong architectural decisions. The refactoring of discovery endpoints into a shared core function shows good code reuse principles. The temporary file management system is well-designed with multiple cleanup mechanisms ensuring reliability.

### Refactoring Performed
No refactoring was necessary. The code follows SOLID principles effectively:
- **Single Responsibility**: Each component has a clear, focused purpose
- **DRY Principle**: Core discovery logic properly extracted and reused
- **Error Handling**: Comprehensive with clear error messages
- **Resource Management**: Excellent cleanup mechanisms for temporary files

### Compliance Check
- Coding Standards: ✓ Follows PEP8, uses type hints, proper docstrings
- Project Structure: ✓ Files properly organized in vertical slice architecture
- Testing Strategy: ✓ Comprehensive unit and integration tests with >80% coverage
- All ACs Met: ✓ All acceptance criteria fully implemented

### Technical Excellence Review

**Strengths:**
1. **Core Logic Refactoring**: The `_process_discovery_core` function effectively consolidates shared logic
2. **Metadata Fix**: Properly resolved the issue where production_metadata was being recreated
3. **Hybrid Storage**: Correctly uses `_store_hybrid_document` for better search capabilities
4. **Temp File Management**: Robust implementation with multiple cleanup strategies:
   - Primary cleanup after processing
   - Error handling cleanup in try/finally blocks
   - Background task for orphaned files
   - Startup cleanup for crash recovery
5. **PDF Validation**: Comprehensive validation including magic bytes, size limits, and encryption checks
6. **WebSocket Events**: Properly structured events for RTP/OC uploads with detailed payloads
7. **Backward Compatibility**: Existing endpoint behavior preserved while adding new functionality

**Architecture Decisions:**
- Temporary storage for RTP/OC files (not in vector DB) is the correct approach
- UUID-based file referencing provides good tracking
- Context manager pattern for temp files ensures cleanup
- Separation of concerns between file validation, storage, and processing

### Security Review
✓ No sensitive data logging
✓ Proper file validation prevents malicious uploads
✓ Case isolation maintained throughout
✓ Temporary files cleaned up securely
✓ No hardcoded credentials or secrets

### Performance Considerations
✓ Asynchronous processing for file operations
✓ Batch processing for vector storage
✓ Efficient cleanup mechanisms that don't block main processing
✓ Configurable file size limits prevent resource exhaustion

### Test Coverage Assessment
The test suite is comprehensive and well-structured:
- Unit tests for all new components
- Integration tests for full workflow
- Error scenario coverage
- WebSocket event testing
- Temp file cleanup verification
- PDF validation edge cases

### Documentation Quality
✓ Excellent API documentation with clear examples
✓ Comprehensive docstrings throughout
✓ WebSocket event structures well documented
✓ Error responses clearly specified

### Final Status
✓ Approved - Ready for Done

The implementation exceeds expectations with robust error handling, comprehensive testing, and excellent architectural decisions. The temporary file management system is particularly well-designed with multiple safeguards against orphaned files.